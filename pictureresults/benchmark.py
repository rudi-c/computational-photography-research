#!/usr/bin/python

# Reads decision trees generated by Weka and evaluate how quickly and how
# accurately they can find peaks.

import getopt
import json
import os
import sys

from coarsefine   import *
from evaluatetree import *
from scene        import *
from rtools       import *
import featuresturn     
import featuresleftright

def make_key(direction, initial_pos, current_pos):
    return direction + "-" + str(initial_pos) + "-" + str(current_pos)

class Evaluator:

    def __init__(self, left_right_tree, first_size_tree,
                 action_tree, step_size, scene,
                 perfect_classification):
        self.left_right_tree = left_right_tree
        self.first_size_tree = first_size_tree
        self.action_tree = action_tree
        self.step_size = step_size
        self.scene = scene
        self.status = [ "none" ] * scene.measuresCount
        self.result = [ -100 ] * scene.measuresCount
        self.visitedPositions = [ [] for pos in scene.measuresValues ]
        if perfect_classification is None:
            self.perfect_classification = None
        else:
            self.perfect_classification = \
                perfect_classification[scene.fileName]

    def _walk_left_fine(self, lens_pos, count=1):
        for i in range(0, count):
            visitedPositions = self.visitedPositions[lens_pos]
            visitedPositions.append(max(0, min(visitedPositions[-1] - 1,
                self.scene.measuresCount)))

    def _walk_left_coarse(self, lens_pos, count=1):
        for i in range(0, count):
            visitedPositions = self.visitedPositions[lens_pos]
            visitedPositions.append(max(0, min(visitedPositions[-1] - 8,
                self.scene.measuresCount)))

    def _walk_right_fine(self, lens_pos, count=1):
        for i in range(0, count):
            visitedPositions = self.visitedPositions[lens_pos]
            visitedPositions.append(max(0, min(visitedPositions[-1] + 1,
                self.scene.measuresCount)))

    def _walk_right_coarse(self, lens_pos, count=1):
        for i in range(0, count):
            visitedPositions = self.visitedPositions[lens_pos]
            visitedPositions.append(max(0, min(visitedPositions[-1] + 8,
                self.scene.measuresCount)))

    def _walk_fine(self, lens_pos, direction, count=1):
        if direction in ("left", -1):
            self._walk_left_fine(lens_pos, count)
        elif direction in ("right", +1):
            self._walk_right_fine(lens_pos, count)
        else:
            assert False, direction

    def _walk_coarse(self, lens_pos, direction, count=1):
        if direction in ("left", -1):
            self._walk_left_coarse(lens_pos, count)
        elif direction in ("right", +1):
            self._walk_right_coarse(lens_pos, count)
        else:
            assert False, direction

    def _max_among(self, lens_positions):
        return max(lens_positions, 
                   key=(lambda pos : self.scene.measuresValues[pos]))

    def _do_local_search(self, lens_pos, maximum_pos, direction, rev_direction):
        visitedPositions = self.visitedPositions[lens_pos]
        while 0 < visitedPositions[-1] < self.scene.measuresCount - 1:
            self._walk_fine(lens_pos, direction, 1)
            if self.scene.measuresValues[visitedPositions[-1]] > \
               self.scene.measuresValues[maximum_pos]:
               maximum_pos = visitedPositions[-1]
            else:
                # Backtrack and stop.
                self._walk_fine(lens_pos, rev_direction, 1)
                break
        return maximum_pos

    def _go_to_max(self, lens_pos, lens_positions):
        current_pos = lens_positions[-1]
        maximum_pos = self._max_among(lens_positions)

        if maximum_pos < current_pos:
            direction = "left"
            rev_direction = "right"
        elif maximum_pos > current_pos:
            direction = "right"
            rev_direction = "left"
        elif current_pos < lens_positions[-2]:
            direction = "left"
            rev_direction = "right"
        else:
            direction = "right"
            rev_direction = "left"

        # Find minimum number of coarse and fine steps needed to go back to
        # the maximum point.
        distance = abs(current_pos - maximum_pos)
        coarse_steps = distance / 8
        self._walk_coarse(lens_pos, direction, coarse_steps)

        # If the remainder is 6-7, we will need to take 6-7 fine steps and it
        # would in theory be better to take a coarse step and go back the other
        # way. Fortunately, in practice this is very rare so we ignore this
        # optimization on the number of lens movements needed to reach the max.
        fine_steps = distance % 8
        potential_maxs = []
        visitedPositions = self.visitedPositions[lens_pos]
        for i in range(fine_steps):
            self._walk_fine(lens_pos, direction, 1)
            potential_maxs.append(visitedPositions[-1])

        assert visitedPositions[-1] == maximum_pos

        if len(potential_maxs) > 0 and \
                self._max_among(potential_maxs) != maximum_pos:
            # Found something better, go back that way.
            self._walk_fine(lens_pos, rev_direction, 
                abs(maximum_pos - self._max_among(potential_maxs)))
            maximum_pos = self._max_among(potential_maxs)
        else:
            # Keep going to see if we can find a higher position.
            maximum_pos = self._do_local_search(lens_pos, 
                maximum_pos, direction, rev_direction)
            # If we didn't take any fine steps at all to get to the
            # max lens position, we should look the other way too.
            if fine_steps == 0:
                maximum_pos = self._do_local_search(lens_pos,
                    maximum_pos, rev_direction, direction)

        self.status[lens_pos] = "foundmax"
        self.result[lens_pos] = maximum_pos

        assert visitedPositions[-1] == maximum_pos

    def _sweep(self, direction, initial_positions):
        # Sweep the lens in one direction.
        assert abs(direction) == 1

        scene = self.scene

        lens_positions = list(initial_positions)
        dir_str = "left" if direction == -1 else "right"
        current_pos = lens_positions[-1]

        # Size of the first step determined by another decision tree.
        if current_pos > 0 and current_pos < scene.measuresCount - 1:
            first  = self.scene.measuresValues[lens_positions[-3]]
            second = self.scene.measuresValues[lens_positions[-2]]
            third  = self.scene.measuresValues[current_pos]
            norm_lens_pos = float(current_pos) / (self.scene.measuresCount - 1)
            evaluator = featuresleftright.leftright_feature_evaluator(
                first, second, third, norm_lens_pos)
            first_size = evaluate_tree(self.first_size_tree, evaluator)

            if first_size == "coarse":
                previously_coarse_step = True
                current_pos = min(scene.measuresCount - 1, 
                                  max(0, current_pos + direction * 8))
            else:
                previously_coarse_step = False
                current_pos = min(scene.measuresCount - 1, 
                                  max(0, current_pos + direction))
            lens_positions.append(current_pos)

        current_pos = lens_positions[-1]

        while current_pos > 0 and current_pos < scene.measuresCount - 1:
            # Determine next step size.
            if previously_coarse_step:
                coarse_now = coarse_if_previously_coarse(
                    scene.measuresValues[current_pos],
                    scene.measuresValues[lens_positions[-2]],
                    scene.measuresValues[lens_positions[-3]])
            else:
                coarse_now = coarse_if_previously_fine(
                    scene.measuresValues[current_pos],
                    scene.measuresValues[lens_positions[-2]],
                    scene.measuresValues[lens_positions[-3]])

            # Move the lens forward.
            if coarse_now:
                current_pos = min(scene.measuresCount - 1, 
                                  max(0, current_pos + direction * 8))
            else:
                current_pos = min(scene.measuresCount - 1, 
                                  max(0, current_pos + direction))
                    
            lens_positions.append(current_pos)
            previously_coarse_step = coarse_now
       
            if self.perfect_classification is None:
                # Obtain the ML classification at the new lens position.
                evaluator = featuresturn.action_feature_evaluator(direction, 
                    self.scene.measuresValues, lens_positions, 
                    self.scene.measuresCount)
                classification = evaluate_tree(self.action_tree, evaluator)
            else:
                classification = self.perfect_classification[make_key(
                    dir_str, lens_positions[0], current_pos)]

            if classification != "continue":
                assert classification == "turn_peak" or    \
                       classification == "backtrack"
                return classification, lens_positions

        # TODO: What should be the default action when an edge is reached?
        return "backtrack", lens_positions

    def _backtrack(self, lens_pos, current_lens_pos):
        """From the current lens position, go back to the lens position we
        were at before and look on the other side."""
        distance_from_initial = abs(lens_pos - current_lens_pos)

        previous_direction_was_left = current_lens_pos < lens_pos

        # We need to reinitialize the list of lens positions used as a feature
        # during the sweep algorithm, to avoid mixing it with the positions
        # of the previous sweep. 
        initial_positions = [lens_pos - self.step_size * 2, 
                             lens_pos - self.step_size, lens_pos]
        if previous_direction_was_left:
            # Go right this time
            new_direction = +1
        else:
            # Go left this time
            new_direction = -1
            initial_positions.reverse()

        # Need to go back to where we were initially at the start of the sweep.
        # It's fine if we overshoot it a little bit if it saves some steps.

        coarse_steps = distance_from_initial / 8
        self._walk_coarse(lens_pos, new_direction, coarse_steps)

        # An extra distance that coarse steps won't reach exactly
        remainder = distance_from_initial % 8
        if remainder > 4:
            # Take more fine steps to reach initial position.
            self._walk_fine(lens_pos, new_direction, 8 - remainder)
        else:
            # Take one big coarse step, which will overshoot a bit.
            self._walk_coarse(lens_pos, new_direction, 1)
            initial_positions.append(self.visitedPositions[lens_pos][-1])

        result, positions = self._sweep(new_direction, initial_positions)

        self.visitedPositions[lens_pos].extend(
            positions[len(initial_positions):])

        if result == "turn_peak":
            self._go_to_max(lens_pos, positions)
        elif result == "backtrack":
            # If we need to backtrack a second time, we failed.
            self.status[lens_pos] = "failed"
        else:
            assert False

    def _evaluate_at_position(self, lens_pos):
        # Decide initial direction in which to look.
        first  = self.scene.measuresValues[lens_pos - self.step_size * 2]
        second = self.scene.measuresValues[lens_pos - self.step_size]
        third  = self.scene.measuresValues[lens_pos]
        norm_lens_pos = float(lens_pos) / (self.scene.measuresCount - 1)

        evaluator = featuresleftright.leftright_feature_evaluator(
            first, second, third, norm_lens_pos)
        direction = evaluate_tree(self.left_right_tree, evaluator)

        initial_positions = [lens_pos - self.step_size * 2, 
                             lens_pos - self.step_size, lens_pos]
        self.visitedPositions[lens_pos].extend(initial_positions)
        if direction == "left":
            initial_positions.reverse()
            result, positions = self._sweep(-1, initial_positions)
        elif direction == "right":
            result, positions = self._sweep(+1, initial_positions)
        else:
            assert False

        self.visitedPositions[lens_pos].extend(
            positions[len(initial_positions):])

        if result == "turn_peak":
            self._go_to_max(lens_pos, positions)
        elif result == "backtrack":
            self._backtrack(lens_pos, positions[-1])
        else:
            assert False

    def evaluate(self):
        """For every scene and every lens position, run a simulation and
        store the statistics."""
        for lens_pos in range(self.step_size * 2, self.scene.measuresCount):
            self._evaluate_at_position(lens_pos)

    def _is_true_positive(self, status, result):
        return status == "foundmax" and \
               self.scene.distance_to_closest_peak(result) <= 1

    def _is_false_positive(self, status, result):
        return status == "foundmax" and \
               self.scene.distance_to_closest_peak(result) > 1

    def _is_true_negative(self, status, visited):
        return status == "failed" and \
               all(self.scene.distance_to_closest_peak(pos) > 1
                   for pos in visited)

    def _is_false_negative(self, status, visited):
        return status == "failed" and \
               any(self.scene.distance_to_closest_peak(pos) <= 1
                   for pos in visited)

    def get_evaluation_at(self, lens_pos):
        status = self.status[lens_pos]
        result = self.result[lens_pos]
        if self._is_true_positive(status, result):
            return "true positive"
        if self._is_false_positive(status, result):
            return "false positive"
        visited = self.visitedPositions[lens_pos]
        if self._is_true_negative(status, visited):
            return "true negative"
        if self._is_false_negative(status, visited):
            return "false negative"

    def count_true_positive(self):
        """Number of instances where a real peak has been marked as found."""
        return sum(self._is_true_positive(status, result) 
                   for status, result in zip(self.status, self.result))

    def count_false_positive(self):
        """Number of instances where a peak marked a found is not a real peak,
        or not close enough to the real peak."""
        return sum(self._is_false_positive(status, result) 
                   for status, result in zip(self.status, self.result))

    def count_true_negative(self):
        """Number of instances where we failed to come close to a peak."""
        return sum(self._is_true_negative(status, visited) for status, visited
                   in zip(self.status, self.visitedPositions))

    def count_false_negative(self):
        """Number of instances where we came close to a peak but ignored it."""
        return sum(self._is_false_negative(status, visited) for status, visited
                         in zip(self.status, self.visitedPositions))


def print_aligned_data_rows(rows):
    """Print rows of data such that each column is aligned."""
    column_lengths = [ len(max(cols, key=len)) for cols in zip(*rows) ]
    for row in rows:
        print "|".join(" " * (length - len(col)) + col
                       for length, col in zip(column_lengths, row))


def benchmark_scenes(left_right_tree, first_size_tree,
                     action_tree, step_size, scenes,
                     perfect_classification):
    evaluators = [ Evaluator(left_right_tree, first_size_tree,
                             action_tree, step_size, scene,
                             perfect_classification) 
                   for scene in scenes ]
    for evaluator in evaluators:
        evaluator.evaluate()

    data_rows = [( "filename", "t-pos", "f-pos", "t-neg", 
                   "f-neg", "%", "steps" )]
    sum_t_pos = 0
    sum_f_pos = 0
    sum_t_neg = 0
    sum_f_neg = 0
    sum_perct = 0
    sum_steps = 0

    for evaluator in evaluators:
        t_pos = evaluator.count_true_positive()
        f_pos = evaluator.count_false_positive()
        t_neg = evaluator.count_true_negative()
        f_neg = evaluator.count_false_negative()
        perct = float(t_pos) / (t_pos + f_pos + t_neg + f_neg) * 100
        steps = float(sum(len(vps) for vps in evaluator.visitedPositions)) / \
                len(evaluator.visitedPositions)

        sum_t_pos += t_pos
        sum_f_pos += f_pos
        sum_t_neg += t_neg
        sum_f_neg += f_neg
        sum_perct += perct
        sum_steps += steps

        data_rows.append((evaluator.scene.name, 
            "%d" % t_pos, "%d" % f_pos, "%d" % t_neg, "%d" % f_neg,
            "%.1f" % perct, "%d" % steps))

    data_rows.append(("average",
        "%.1f" % (float(sum_t_pos) / len(evaluators)),
        "%.1f" % (float(sum_f_pos) / len(evaluators)),
        "%.1f" % (float(sum_t_neg) / len(evaluators)),
        "%.1f" % (float(sum_f_neg) / len(evaluators)),
        "%.1f" % (float(sum_perct) / len(evaluators)),
        "%.1f" % (float(sum_steps) / len(evaluators))))

    print_aligned_data_rows(data_rows)


def benchmark_specific(left_right_tree, first_size_tree,
                       action_tree, step_size, 
                       scenes, specific_scene, perfect_classification):
    for scene in scenes:
        if scene.fileName == specific_scene:
            evaluator = Evaluator(left_right_tree, first_size_tree,
                                  action_tree, 
                                  step_size, scene, perfect_classification)
            evaluator.evaluate()

            for lens_pos in range(2 * step_size, scene.measuresCount):
                print_R_script(scene, lens_pos, 
                    evaluator.visitedPositions[lens_pos],
                    evaluator.get_evaluation_at(lens_pos),
                    evaluator.result[lens_pos])


def print_R_script(scene, lens_pos, visitedPositions, evaluation, result):

    print "# %s at %d, %s\n" % (scene.fileName, lens_pos, evaluation)

    # Some R functions for plotting.
    print_set_window_division(1, 1)
    print "library(scales)" # for alpha blending

    print_plot_focus_measures(scene.measuresValues, show_grid=True)

    xs = visitedPositions
    ys = [ float(i) / max(10, len(visitedPositions))
           for i in range(0, len(visitedPositions)) ]

    print_plot_point_pairs(xs, ys, 25, "blue", "blue", True)

    if result >= 0:
        print "segments(%d, 0.0, %d, 1.0)" % (result, result)

    print "\n# Plot me!\n"


def load_classifications(filename):
    try:
        f = open(filename)
        lines = f.readlines()
        f.close()
    except IOError:
        raise Exception("File " + filename + " not found.")
    return json.loads("".join(lines))


def print_script_usage():
   print  """Script usage : ./makegroundtruthcomparison.py 
             --left-right-tree=<decision tree for deciding left vs right>
             --first-size-tree=<decision tree for deciding first coarse vs fine>
             --action-tree=<decision tree for deciding action to take>]
             [-d, --double-step <double step size used>]
             [--specific-scene=<a scene's filename, will print R script]
             [--perfect-file=<use classification from file instead of tree>]"""


def main(argv):

    if not os.path.isdir(scenes_folder):
        print scenes_folder + " folder not found."
        return

    # Parse script arguments
    try:
        opts, args = getopt.getopt(argv, "d",
            ["left-right-tree=", "first-size-tree=",
             "action-tree=", "double-step",
             "specific-scene=", "perfect-file="])
    except getopt.GetoptError:
        print_script_usage()
        sys.exit(2)

    step_size = 1
    left_right_tree = None
    first_size_tree = None
    action_tree = None
    specific_scene = None
    perfect_classification = None

    for opt, arg in opts:
        if opt == "--double-step":
            step_size = 2
        elif opt == "--left-right-tree":
            features = { name : function 
                for name, _, function in featuresleftright.all_features() }
            left_right_tree = read_decision_tree(arg, features)
        elif opt == "--first-size-tree":
            features = { name : function 
                for name, _, function in featuresleftright.all_features() }
            first_size_tree = read_decision_tree(arg, features)
        elif opt == "--action-tree":
            features = { name : function 
                for name, function in featuresturn.all_features() }
            action_tree = read_decision_tree(arg, features)
        elif opt == "--specific-scene":
            specific_scene = arg
        elif opt == "--perfect-file":
            perfect_classification = load_classifications(arg)
        else:
            print_script_usage()
            sys.exit(2)

    if (left_right_tree is None or first_size_tree is None 
                                or action_tree is None) and \
            perfect_classification is None:
        print_script_usage()
        sys.exit(2)

    scenes = load_scenes(excluded_scenes=["cat.txt", "moon.txt"])
    load_maxima_into_measures(scenes)

    if specific_scene is None:
        benchmark_scenes(left_right_tree, first_size_tree,
            action_tree, step_size, scenes,
            perfect_classification)
    else:
        benchmark_specific(left_right_tree, first_size_tree,
                           action_tree, step_size, scenes,
                           specific_scene, perfect_classification)


main(sys.argv[1:])